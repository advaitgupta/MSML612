# Drone Transformer RL

Autonomous drone navigation with a **Transformer-based Reinforcement-Learning policy**.

This repository accompanies the MSML 612 group project (University of Maryland). It contains **fully-reproducible code**, a Streamlit demo, HPC SLURM job scripts, and comprehensive documentation.

---

## 1. Problem statement
Modern UAVs must avoid obstacles, regulate velocity, and remain on course in dynamic 3-D environments. Rule-based controllers struggle with unseen situations. We solve this by coupling:

1. **Sequence modelling** â€“ a deep Transformer encoder captures long-term temporal dependencies in state trajectories.  
2. **Reinforcement learning** â€“ PPO trains the policy through interaction with high-fidelity simulators (FlyCraft Gym, AirSim Drone Racing Lab).

---

## 2. Key contributions
- **Hierarchical Transformer Policy** â€“ multi-scale attention, relative position encodings, windowed memory and Transformer-XL recurrence for superior long-horizon reasoning.
- **Curriculum & Domain Randomisation** â€“ progressive task difficulty and environment variability for strong generalisation.
- **Knowledge Distillation** â€“ large teacher â†’ lightweight student for real-time inference on embedded hardware.
- **Optuna Hyper-parameter Sweeps** â€“ automated search across depth, heads, dropout and RL coefficients.
- **On-policy Data Augmentation** â€“ sensor noise injection, adversarial wind gusts.
- **Streamlit Live Demo** â€“ run a trained student model directly in the browser and visualise flight metrics in real-time.
- **Perceiver IO + ACT** â€“ modality-aware Perceiver cross-attention fuses position / velocity / lidar.  
  Adaptive Computation Time lets â€œeasyâ€ states exit early, cutting average latency while maintaining performance.  
- **Contrastive Pre-training** â€“ optional self-supervised phase on raw flight logs before RL fine-tuning.

---

## 3. Repository structure
```
drone_transformer_rl/
â”œâ”€â”€ src/                # Python packages (importable as drone_rl)
â”‚   â”œâ”€â”€ data/           # Simulation, logging, augmentation
â”‚   â”œâ”€â”€ models/         # Transformer architectures
â”‚   â”œâ”€â”€ train/          # Training & evaluation loops
â”‚   â”œâ”€â”€ utils/          # Helpers & metrics
â”œâ”€â”€ configs/            # YAML/JSON config files
â”œâ”€â”€ demo/               # Streamlit app
â”œâ”€â”€ slurm/              # Example HPC job scripts for zaratan@umd
â”œâ”€â”€ notebooks/          # Optional exploratory notebooks
â”œâ”€â”€ tests/              # Unit tests / smoke tests
â”œâ”€â”€ env.yml             # Conda environment spec (CUDA & CPU)
â”œâ”€â”€ RUN_GUIDE.md        # End-to-end instructions
â””â”€â”€ README.md           # You are here
```

---

## 4. Quickstart (local GPU)

```bash
# 1. Create environment (CUDA 12.1 build â€“ adjust if your GPU uses 11.x)
conda env create -f env.yml
conda activate drone-rl

# 2. Generate a dataset (â‰ˆ 10 min for 3 k episodes)
python -m drone_rl.data.generate_dataset --out data/raw --episodes 3000

# 3. Train teacher policy (Transformer-XL-Large)
python -m drone_rl.train.train --config configs/teacher_large.yaml

# 4. Distil to student + evaluate
python -m drone_rl.train.train --config configs/student_distilled.yaml
python -m drone_rl.train.evaluate --model runs/student/best.pt

# 5. (Optional) Train Perceiver + ACT sensor-fusion policy
python -m drone_rl.train.train --config configs/perceiver_act.yaml

# 5. Launch the Streamlit demo
streamlit run demo/app.py -- --checkpoint runs/student/best.pt

# Train the LSTM baseline (example)
# Run this from the repo root and ensure PYTHONPATH includes `src`.
```bash
PYTHONPATH=src python -m src.drone_rl.train.train_lstm --config configs/baseline_lstm.yaml
```
```


## 5. Quickstart on **zaratan@umd** (SLURM HPC)

```bash
# Login and clone
ssh <netid>@zaratan.umd.edu
git clone <repo-url> drone_transformer_rl
cd drone_transformer_rl

# Load CUDA module that matches available A100 GPUs
module load cuda/12.1  gcc/11.3

# Create Conda env in scratch
conda env create -f env.yml -p $HOME/conda/envs/drone-rl
conda activate $HOME/conda/envs/drone-rl

# Submit a job (single-GPU)
sbatch slurm/train_teacher_a100.sbatch
```

Job scripts automatically resume from checkpoints and copy logs to `$SCRATCH/drone_logs`. See `slurm/README.md` for multi-GPU and Optuna sweep variants.

---

## 6. Evaluation metrics
The following metrics are logged each episode and summarised in `wandb`/CSV:

| Metric | Purpose |
|--------|---------|
| Time-to-Collision (â†‘) | Safety buffer before impact |
| Path Deviation (â†“) | Route fidelity using DTW distance |
| Course Completion Time (â†“) | Task efficiency |
| Success Rate on Unseen Paths (â†‘) | Generalisation |
| Distillation Accuracy Retention (â†‘) | Student vs Teacher gap |

---


## 7. License
This repository is released under the MIT License. Refer to `LICENSE` for details.

Happy flying! ğŸš
